{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is the prompting notebook for commonsense_qa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple \n",
    "        \"Instruction: This is a multiple choice question and you are required to answer with the letter corresponding to the correct choice.\\nQuestion: {question}\\nConcept: {concept}\\nChoices: {', '.join(choice_strings)}\\nYour Answer: \"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cot\n",
    "        \"Instruction: This is a multiple choice question and you are required to answer with the letter corresponding to the correct choice.\\n\"\n",
    "        f\"Question: {question}\\nConcept: {concept}\\nChoices: {', '.join(choice_strings)}\\n\"\n",
    "        \"Let's think step by step. Please provide your answer followed by your thinking steps.\"\n",
    "        \"Your Answer:  \"\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ICL (No Reasoning)\n",
    "        \"Instruction: This is a multiple choice question. Please answer with the letter corresponding to the correct choice.\\n\\n\"\n",
    "        \n",
    "        \"Here are some examples of questions with their correct answers and reasoning:\\n\\n\"\n",
    "        \n",
    "        \"{\\n\"\n",
    "        \"Example Question 1: The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change?\\n\"\n",
    "        \"Concept: punishing\\n\"\n",
    "        \"Choices: { A: Ignore, B: Enforce, C: Authoritarian, D: Yell at, E: Avoid }\\n\" \n",
    "        \"Answer: A\\n\"\n",
    "        \"}\\n\\n\"\n",
    "        \n",
    "        \"{\\n\"\n",
    "        \"Example Question 2: Sammy wanted to go to where the people were. Where might he go?\\n\"\n",
    "        \"Concept: people\\n\"\n",
    "        \"Choices: { A: Race track, B: Populated areas, C: The desert, D: Apartment, E: Roadblock }\\n\" \n",
    "        \"Answer: B\\n\"\n",
    "        \"}\\n\\n\" \n",
    "\n",
    "        \"{\\n\"\n",
    "        \"Example Question 3: Google Maps and other highway and street GPS services have replaced what?\\n\"\n",
    "        \"Concept: highway\\n\"\n",
    "        \"Choices: { A: United States, B: Mexico, C: Countryside, D: Atlas, E: Oceans }\\n\" \n",
    "        \"Answer: D\\n\"\n",
    "        \"}\\n\\n\"\n",
    "        \n",
    "        f\"Now, let's solve this question:\\n\"\n",
    "        f\"Question: {question}\\n\"\n",
    "        f\"Concept: {concept}\\n\"\n",
    "        f\"Choices: {', '.join(choice_strings)}\\n\"\n",
    "        \"Please provide your answer followed by your reasoning as above.\\n\"\n",
    "        \"Your Answer: \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ICL (Reasoning)\n",
    "        \"Instruction: This is a multiple choice question and you are required to answer with the letter corresponding to the correct choice.\\n\"\n",
    "        \n",
    "        \"There are a few examples of questions, the correct answers, and reasonings:\\n\"\n",
    "        \n",
    "        \"{\\n\"\n",
    "        \"Example Question 1: The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change?\\n\"\n",
    "        \"Concept: punishing\\n\"\n",
    "        \"Choices: { A: Ignore, B: Enforce, C: Authoritarian, D: Yell at, E: Avoid }\\n\" \n",
    "        \"Answer: A\\n\"\n",
    "        \"Reasoning:\\n\"\n",
    "        \"- The phrase 'punishing blow' indicates a negative impact on the school.\\n\"\n",
    "        \"- 'Seemed to' suggests that the sanctions overlooked the school's efforts.\\n\"\n",
    "        \"- 'Ignore' is correct as it means to disregard, aligning with the context of the sanctions.\\n\"\n",
    "        \"}\\n\\n\"\n",
    "        \n",
    "        \"{\\n\"\n",
    "        \"Example Question 2: Sammy wanted to go to where the people were. Where might he go?\\n\"\n",
    "        \"Concept: people\\n\"\n",
    "        \"Choices: { A: Race track, B: Populated areas, C: The desert, D: Apartment, E: Roadblock }\\n\" \n",
    "        \"Answer: B\\n\"\n",
    "        \"Reasoning:\\n\"\n",
    "        \"- 'Where the people were' indicates Sammy seeks a location with many people.\\n\"\n",
    "        \"- 'Populated areas' directly aligns with this intention, as these places have a high density of people.\\n\"\n",
    "        \"}\\n\\n\"\n",
    "        \n",
    "        \"{\\n\"\n",
    "        \"Example Question 3: Google Maps and other highway and street GPS services have replaced what?\\n\"\n",
    "        \"Concept: highway\\n\"\n",
    "        \"Choices: { A: United States, B: Mexico, C: Countryside, D: Atlas, E: Oceans }\\n\" \n",
    "        \"Answer: D\\n\"\n",
    "        \"Reasoning:\\n\"\n",
    "        \"- Google Maps and other GPS services are used for navigating highways and streets.\\n\"\n",
    "        \"- 'Atlas' refers to a collection of physical maps, which were used for navigation before digital GPS systems.\\n\"\n",
    "        \"- 'Atlas' is the correct answer because GPS services have replaced the need for traditional map books and atlases.\\n\"\n",
    "        \"}\\n\\n\"\n",
    "\n",
    "        f\"\\n\\nNow, let's solve this one:\\nQuestion: {question}\\nConcept: {concept}\\nChoices: {', '.join(choice_strings)}\\nYour Answer: \"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llava",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
